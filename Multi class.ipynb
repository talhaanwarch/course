{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32896bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-12 01:29:59.251427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pytorch_lightning import seed_everything, LightningModule, Trainer\n",
    "from sklearn.utils import class_weight\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from pytorch_lightning.callbacks import EarlyStopping,ModelCheckpoint,LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import  ReduceLROnPlateau\n",
    "import torchvision\n",
    "from sklearn.metrics import classification_report,f1_score,accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, Dataset,ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d97b290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=512\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "aug= A.Compose([\n",
    "            A.Resize(img_size+32,img_size+32),\n",
    "            A.RandomCrop(img_size,img_size),\n",
    "            A.HorizontalFlip(0.5),\n",
    "            A.VerticalFlip(0.5),\n",
    "            A.ShiftScaleRotate(rotate_limit=3),\n",
    "            A.Blur(),A.RandomGamma(),\n",
    "            A.Sharpen(), A.GaussNoise(),\n",
    "            A.CoarseDropout(8,64,64),\n",
    "            A.CLAHE(0.5),\n",
    "            A.Normalize(mean=(0), std=(1)),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71df8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x=self.dataset[index][0]\n",
    "        y=self.dataset[index][1]\n",
    "        if self.transform:\n",
    "            x=np.array(x)\n",
    "            x=cv2.cvtColor(src=x, code=cv2.COLOR_RGB2GRAY)\n",
    "            x=self.transform(image=x)['image']\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae0e4a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torchmetrics\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import random_split\n",
    "import torchxrayvision as xrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a552ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurModel(LightningModule):\n",
    "    def __init__(self,combined,train_subsampler,test_subsampler):\n",
    "        super(OurModel,self).__init__()\n",
    "        #architecute\n",
    "        self.model = xrv.models.ResNet(weights=\"resnet50-res512-all\")\n",
    "        self.model.model.fc=nn.Sequential(nn.Linear(2048,512),nn.ReLU(),\n",
    "                              nn.Linear(in_features=512, out_features=3),\n",
    "                              )\n",
    "        \n",
    "        self.model=self.model.model\n",
    "        self.train_subsampler=train_subsampler\n",
    "        self.test_subsampler=test_subsampler\n",
    "        self.combined=combined\n",
    "        \n",
    "        #parameters\n",
    "        self.lr=1e-3\n",
    "        self.batch_size=24\n",
    "        self.numworker=4\n",
    "        self.acc = torchmetrics.Accuracy()\n",
    "        self.criterion=nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.trainacc,self.valacc=[],[]\n",
    "        self.trainloss,self.valloss=[],[]\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x= self.model(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt=torch.optim.AdamW(params=self.parameters(),lr=self.lr )\n",
    "        scheduler=ReduceLROnPlateau(opt,mode='min', factor=0.75, patience=5)\n",
    "        return {'optimizer': opt,'lr_scheduler':scheduler,'monitor':'val_loss'}\n",
    "        \n",
    " \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(DataReader(self.combined,aug), batch_size = self.batch_size, \n",
    "                          num_workers=self.numworker,sampler=self.train_subsampler,pin_memory=True,shuffle=False)\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        image,label=batch\n",
    "        out = self(image)\n",
    "        loss=self.criterion(out,label)\n",
    "        acc=self.acc(out,label)\n",
    "        return {'loss':loss,'acc':acc}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        acc=torch.stack([x[\"acc\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        self.trainacc.append(acc)\n",
    "        self.trainloss.append(loss)\n",
    "        print('training loss accuracy ',self.current_epoch,loss, acc)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        ds=DataLoader(DataReader(self.combined,aug), batch_size = self.batch_size,\n",
    "                      num_workers=self.numworker,pin_memory=True,sampler=self.test_subsampler, shuffle=False)\n",
    "        return ds\n",
    "\n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        image,label=batch\n",
    "        out=self(image)\n",
    "        loss=self.criterion(out,label)\n",
    "        acc=self.acc(out,label)\n",
    "        return {'loss':loss,'acc':acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        loss=torch.stack([x[\"loss\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        acc=torch.stack([x[\"acc\"] for x in outputs]).mean().detach().cpu().numpy().round(2)\n",
    "        self.valacc.append(acc)\n",
    "        self.valloss.append(loss)\n",
    "        print('validation loss accuracy ',self.current_epoch,loss, acc)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27ab96b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary\tcode  intro.odp  multiclass\r\n"
     ]
    }
   ],
   "source": [
    "!ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08cc8104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21390\n"
     ]
    }
   ],
   "source": [
    "train_split=torchvision.datasets.ImageFolder('../multiclass/train/')\n",
    "val_split=torchvision.datasets.ImageFolder('../multiclass/validation/')\n",
    "combined=ConcatDataset([train_split,val_split])\n",
    "print(len(combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28db24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5,random_state=21,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "878a2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------fold no---------0----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "[W Context.cpp:69] Warning: torch.set_deterministic is in beta, and its design and  functionality may change in the future. (function operator())\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss accuracy  0 0.32 0.91\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 VALIDATE RESULTS\n",
      "{'val_acc': 0.9100000262260437, 'val_loss': 0.3199999928474426}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for fold,(train_idx,val_idx) in enumerate(kfold.split(combined)):\n",
    "    print('------------fold no---------{}----------------------'.format(fold))\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "\n",
    "\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "    model=OurModel(combined,train_subsampler,val_subsampler)\n",
    "    \n",
    "    trainer = Trainer(max_epochs=30,\n",
    "                    deterministic=True,\n",
    "                    gpus=-1,precision=16,\n",
    "                    accumulate_grad_batches=4,\n",
    "                    progress_bar_refresh_rate=0,\n",
    "                    callbacks=[lr_monitor],\n",
    "                    num_sanity_val_steps=0,\n",
    "                    )\n",
    "    #trainer.fit(model)\n",
    "    #torch.save(model.state_dict(), '../multiclass/last_{}.pth'.format(fold))\n",
    "    \n",
    "    model.load_state_dict(torch.load('../multiclass/last_{}.pth'.format(fold)))\n",
    "    trainer.validate(model)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea5ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfcc072",
   "metadata": {},
   "source": [
    "```\n",
    "\"Accuracy_score\": 0.9358333333333333,\n",
    "\"Sensitivity_score\": 0.9358333333333334,\n",
    "\"Specificity_score\": 0.9382374634526824\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d4f86e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
